{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-massive-world/music_video/blob/main/planet_translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POcVhmAT2RIm"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output as clear\n",
        "import json, os, time\n",
        "ifile = 'installed_libraries.json'\n",
        "try:\n",
        "  with open(ifile,'r') as f:\n",
        "    i_file = json.load(f)\n",
        "  \n",
        "  print('I already have the necessary libraries. ^-^\\n')\n",
        "except FileNotFoundError:\n",
        "  \n",
        "\n",
        "  print('I am installing libraries\\n')\n",
        "  \n",
        "\n",
        "  import time\n",
        "  import os\n",
        "\n",
        "  # !python -m pip uninstall Pillow -y\n",
        "  # !pip install Pillow==8.2.0\n",
        "  # !pip install spotipy --upgrade\n",
        "  # !pip install qrcode[pil]\n",
        "  !pip install fonttools\n",
        "  clear()\n",
        "\n",
        "  !pip install humanfriendly\n",
        "  !pip install ffmpeg-python\n",
        "  !pip install xlsxwriter\n",
        "  # !pip install py-deezer\n",
        "  # !pip install pydub\n",
        "  !pip install -U ipython\n",
        "  # !pip install lyricsgenius\n",
        "  clear()\n",
        "  clear()\n",
        "  with open(ifile,'w') as f:\n",
        "    json.dump('1',f)\n",
        "\n",
        "  # time.sleep(3)\n",
        "  os.kill(os.getpid(),9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzVpeuMWgdqN"
      },
      "outputs": [],
      "source": [
        "import os,json,requests,re,random,time\n",
        "from urllib.parse import quote\n",
        "from IPython.display import clear_output as clear\n",
        "import unicodedata\n",
        "from datetime import date as datetimedate\n",
        "from humanfriendly import format_timespan, format_size\n",
        "from PIL import ImageDraw, Image, ImageFont, ImageOps\n",
        "# from pydeezer import Deezer, Downloader\n",
        "# from pydeezer.constants import track_formats\n",
        "from IPython.display import Audio, Image as im, clear_output as clear, Video\n",
        "# from IPython.display import Video\n",
        "# from datetime import date as datetimedate, datetime\n",
        "# from bs4 import BeautifulSoup as bsp\n",
        "# import random, qrcode, re, lyricsgenius, requests, math,pytz\n",
        "import string as st, json, time, textwrap, os,shutil,math\n",
        "# import unicodedata\n",
        "# from urllib.parse import quote\n",
        "from fontTools.ttLib import TTFont as ttfont\n",
        "# from fontTools.unicode import Unicode\n",
        "# from mutagen.mp3 import MP3\n",
        "# from pydub import AudioSegment\n",
        "# from contextlib import redirect_stderr\n",
        "# from fontTools import ttLib\n",
        "# import spotipy\n",
        "# from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "\n",
        "empty_list = ['',\"\",\" \",' ']\n",
        "allowed_punct = [\"(\",\")\",\"?\",\"!\",\"‚Äô\",\"‚Äò\",\"‚Äú\",\"‚Äù\",\".\",\"¬ø\"]\n",
        "non_space_punct = [\"?\",\"!\",\",\",\";\",\"-\",'.',\".\"]\n",
        "sa = ['NotoSerifDevanagari-Regular.ttf','NotoSerifBengali-Regular.ttf']\n",
        "left_side = [\"‚Äò\",\"‚Äú\",\"(\",\"¬ø\"]\n",
        "right_side = [\"‚Äù\",\"‚Äô\",\")\"]\n",
        "lst = ['&\\u200b','Featuring\\u200b','Released\\u200b', 'on\\u200b','Produced\\u200b', 'by\\u200b','On\\u200b']\n",
        "\n",
        "##### THE FOLDERS 'ALL_FONTS', 'unlimited_ssm', 'My_Music' SHOULD BE IN DRIVE\n",
        "\n",
        "separator = ' ‚Äî‚Äî '\n",
        "sep = ' ‚Äî '\n",
        "fd = 'font_database'\n",
        "da = 'deezer_appendix'\n",
        "lyrics_sync = ''\n",
        "slsd = 'song_lyrics_sync_dictionary'\n",
        "dmd = 'downloaded_music_database'\n",
        "sid = 'song_info_database'\n",
        "default = 'NotoSans-Regular.ttf'\n",
        "font_path = '/content/drive/MyDrive/essentials/ALL_FONTS/'\n",
        "dynamic_range = [0,255]\n",
        "color = (154,154,154)\n",
        "placeholder_images = '/content/placeholder_images/'\n",
        "video_path = '/content/drive/MyDrive/essentials/unlimited_ssm/---archive---/video/'\n",
        "key_destination = '/content/drive/MyDrive/essentials/unlimited_ssm/---archive---/video/'\n",
        "p1 ='\\'!\"(),*+.:%‚Äú;<!¬¨~=>?[\\\\]^_`‡•§{|}‡•§~ÿåÿü¬ø¬°‚ÄùÔºàÔºâ‚Äò‚ÄôÔºüÔºÅ'\n",
        "p2 ='\\*+:;<‡•§¬¨~=>[\\\\]?!^_`‡•§{|}~ÿåÿü¬ø¬°Ôºü'\n",
        "m = '/content/drive/MyDrive/essentials/ALL_FONTS/merged.ttf'\n",
        "n = '/content/drive/MyDrive/essentials/ALL_FONTS/'\n",
        "td = 'translation_database'\n",
        "number_of_requests = 10000000000\n",
        "maximum_allowed_character_length = 1000000000\n",
        "time_to_sleep = 0\n",
        "\n",
        "if os.path.exists(placeholder_images) is False:\n",
        "  os.mkdir(placeholder_images)\n",
        "\n",
        "if os.path.exists(video_path) is False:\n",
        "  os.mkdir(video_path)\n",
        "\n",
        "if os.path.exists('/content/SYNC_MUSIC/') is False:\n",
        "  os.mkdir('/content/SYNC_MUSIC/')\n",
        "\n",
        "if os.path.exists('/content/sample_data/') is True:\n",
        "  shutil.rmtree('/content/sample_data/')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djtb9sFTnFYY"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "# k = datetime.now((\"Etc/GMT-6\"))\n",
        "k = int(datetime.utcnow().timestamp())\n",
        "# time.sleep(2)\n",
        "j = int(datetime.utcnow().timestamp())\n",
        "(j-k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNyhSS6hgmIT"
      },
      "outputs": [],
      "source": [
        "def get_sd():\n",
        " return to_json({},'song_details','read')\n",
        "\n",
        "def to_json(dic, name, string):\n",
        "  path = '/content/drive/MyDrive/essentials/unlimited_ssm/---archive---/jsons/'\n",
        "  a = 1\n",
        "  if string == 'write':\n",
        "    \n",
        "    if dic == {}:\n",
        "      print('Given Dictionary is empty. Check again!!')\n",
        "      return False\n",
        "    if a == 1:  \n",
        "\n",
        "      with open(path+name+'.json','w') as fp:\n",
        "        json.dump(dic,fp)\n",
        "    else:\n",
        "      print('Did not save anything.')\n",
        "      return False\n",
        "    \n",
        "    # print('saved '+name+'.json')\n",
        "    print('saved',sep,name,'('+getfilesize(path+name+'.json',1)+')')\n",
        "\n",
        "  if string == 'read':\n",
        "    with open(path+name+'.json','r') as fp:\n",
        "      data = json.load(fp)\n",
        "    \n",
        "    return data\n",
        "\n",
        "\n",
        "def getfilesize(the_file,the_type):\n",
        "  file_size = os.path.getsize(the_file)\n",
        "  actual_file_size = format_size(file_size)\n",
        "\n",
        "  la_output = the_file.split('/')[-1]+sep+actual_file_size\n",
        "  \n",
        "  if the_type not in empty_list:\n",
        "    if the_type == 1:\n",
        "      return la_output.split(sep)[-1]\n",
        "    else:\n",
        "      return file_size\n",
        "  else:\n",
        "    print(la_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYROnbtWgxC0"
      },
      "outputs": [],
      "source": [
        "def test_line():\n",
        "  the_line = ''\n",
        "\n",
        "  while the_line in empty_list:\n",
        "      \n",
        "    s = to_json({},slsd,'read')\n",
        "    song_keys = list(s.keys())\n",
        "    rand_index = random.randint(0,len(song_keys)-1)\n",
        "    choosen_song_index = song_keys[rand_index]\n",
        "    the_song  = s[str(choosen_song_index)]\n",
        "    lines = the_song.split('\\n')[0::2]\n",
        "    choosen_line_index = random.randint(0,len(lines))\n",
        "    try:\n",
        "      the_line = lines[choosen_line_index].split(']')[-1]\n",
        "    except IndexError:\n",
        "      continue\n",
        "  return the_line\n",
        "  \n",
        "try:\n",
        "  if timercircuit == 1:\n",
        "    timercircuit = 1\n",
        "except NameError:\n",
        "  to_json((0,0,int(datetime.utcnow().timestamp())),'timer_circuit','write')\n",
        "  timercircuit = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDrGJrY_j8gJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def normalize_keys(dictionary):\n",
        "  lst = list(dictionary.keys())\n",
        "  for item in lst:\n",
        "    # print(item)\n",
        "    new_key = norm(str(item))\n",
        "    dictionary[new_key]=dictionary.pop(item)\n",
        "\n",
        "  return dictionary\n",
        "def norm(a):\n",
        "  a = a.split()\n",
        "  \n",
        "  w = bytes('',encoding='utf-8')\n",
        "  for word in a:\n",
        "    my_unicode = word\n",
        "    my_unicode = my_unicode.strip('/')\n",
        "    my_unicode = my_unicode.replace('/','')\n",
        "    output = unicodedata.normalize('NFD', my_unicode).encode('ascii', 'ignore')\n",
        "    # display(w,output)\n",
        "    if output in [b'']:\n",
        "      w+=bytes(word+' ',encoding='utf-8')\n",
        "    else:\n",
        "      w+=output+bytes(' ',encoding='utf-8')\n",
        "\n",
        "  \n",
        "  return w.strip()\n",
        "def zero_width_cleaner(s,is_this_lyrics):\n",
        "  zw = [\"\\u200b\",\"\\xa0\",\"\\u2005\",\"\\u2006\",\"\\u2026\",\"\\u3000\",\"\\u300b\"]\n",
        "  zws = [\"\\u2005\",\"\\u2006\",\"\\u300b\",\"\\u3000\",\"\\u2026\",\"ÔΩ•ÔΩ•ÔΩ•\"]\n",
        "  if is_this_lyrics not in empty_list:\n",
        "    # p1 ='\\'!\"(),*+.:%‚Äú;<!¬¨~=>?[\\\\]^_`‡•§{|}‡•§~ÿåÿü¬ø¬°‚ÄùÔºàÔºâ‚Äò‚ÄôÔºüÔºÅ'\n",
        "    # s = s.translate(str.maketrans(\" \",\" \",p1))\n",
        "    # print(s)\n",
        "    try:\n",
        "      s = s.replace(\"ÔºÅ\",\"! \")\n",
        "    except Exception as e:\n",
        "      clear()\n",
        "      print(s)\n",
        "      print('Song index: ',index)\n",
        "\n",
        "      print('Run planet_translate, google forsaken us!!! The lyrics one, perhaps.')\n",
        "\n",
        "  for word in zw:\n",
        "    if word in zws:\n",
        "      # s = re.sub(word,\" \",s)\n",
        "      s = s.replace(word,\" \")\n",
        "    else:\n",
        "      s = re.sub(word,\"\",s)  \n",
        "  \n",
        "  regex = r\"([0-9].[0-9]+[a-zA-Z]|[0-9]|[0-9][a-zA-Z])+(EmbedShare|Embed)| URLCopyEmbedCopy|EmbedShare|Embed\" #https://regex101.com/r/WmB5iV/2\n",
        "  s= re.sub(regex,\"\",s,0,re.MULTILINE)\n",
        "  # s = re.sub(r\"[0-9]+EmbedShare URLCopyEmbedCopy\",\"\",s)                              \n",
        "  # # s = re.sub(r\"([0-9]\\.[0-9]+[a-zA-Z]|[0-9]|[0-9][a-zA-Z])+Embed|\\Embed\",\"\",s)\n",
        "  # s = re.sub(r\"[0-9]+Embed\",\"\",s)\n",
        "  # s = re.sub(r\"EmbedShare URLCopyEmbedCopy\",\"\",s)\n",
        "  # s = re.sub(r\"EmbedShare\",\"\",s)\n",
        "  # s = re.sub(r\"Embed\",\"\",s)\n",
        "  \n",
        "\n",
        "  s = re.sub(r\"[\\[].*?[]]\",\"\",s)\n",
        "  \n",
        "  a= re.sub(\"Ôºà\",\"(\",s)\n",
        "  a=re.sub(\"Ôºâ\",\")\",a)\n",
        "  a = re.sub(\"Ôºü\",\"?\",a)\n",
        "  # if is_this_lyrics == 1:  \n",
        "  a= re.sub(r\"\\s[\\\"\\'\\‚Äò\\‚Äô\\‚Äù\\‚Äú](?!\\w)|^[\\']\\s\",\"\",a) #### kills rogue apostrophes #https://regex101.com/r/TyfvO3/2\n",
        "\n",
        "\n",
        "  a = re.sub(r\"\\‚Äù(?!\\w)\",\"‚Äù\",a)\n",
        "  a = re.sub(r\"\\'(?!\\w)\",\"‚Äô\",a)\n",
        "  a = re.sub(r\"\\\"(?!\\w)\",\"‚Äù\",a)\n",
        "  a = re.sub(r\"‚Ä≤\",\"‚Äô\",a)\n",
        "\n",
        "  a = re.sub(r\"(?<!\\w)\\\"\",\"‚Äú\",a)\n",
        "  # a = re.sub(r\"[^\\S]?(\\(.*?\\))[^\\S]?\", r\" \\1 \", a).strip() ## puts space before parenthesis\n",
        "\n",
        "  a = re.sub('\\'','‚Äô',a)\n",
        "  # a = re.sub('.','',a)\n",
        "  a = re.sub('\\\"','‚Äú',a)\n",
        "\n",
        "  a = re.sub(r\"(?<!\\w)\\‚Äô\",'‚Äò',a)\n",
        "  \n",
        "  # a = re.sub(r\"(?<!\\w)\\‚Äù\",\"‚Äú\",a)\n",
        "\n",
        "  s = a\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URgpPE-ppF4_"
      },
      "outputs": [],
      "source": [
        "def delete_from_translation_file():\n",
        "  \n",
        "  index = input('SONG INDEX NO. ')\n",
        "  \n",
        "  if index in empty_list:\n",
        "    return 'BAIIII'\n",
        "  lyrics = s[index]['lyrics']\n",
        "  print('Removing',index,sep,to_json({},sid,'read')[index]['song_name'])\n",
        "  kl = to_json({},'translation_database','read')\n",
        "  c = int(input('Enter 934 to delete: '))\n",
        "  if c==934:\n",
        "    for item in lyrics.split('\\n'):\n",
        "      if item not in empty_list:\n",
        "        try:\n",
        "          kl.pop(item.strip())\n",
        "          print('Deleted',item)\n",
        "        except KeyError:\n",
        "          continue\n",
        "    to_json(kl,'translation_database','write')\n",
        "  else:\n",
        "    print('DID NOT DELETE. BAI.')\n",
        "# delete_from_translation_file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPnM_5-n0QXJ"
      },
      "outputs": [],
      "source": [
        "def fragile_translator_machine(word):\n",
        "    # word = 'Suerte que en sur hayas nachido'\n",
        "  # print('Translating',sep,word)\n",
        "  chart = len(word.split()[0::2])\n",
        "  if chart == 1:\n",
        "    chart=2\n",
        "  \n",
        "  chart = 3\n",
        "  if word == '\\u200b' or word=='\\u200b\\u200b' or word in empty_list:\n",
        "    return '\\u200b','\\u200b'\n",
        "  # print('sleep time',sep,chart)\n",
        "  # url = \"https://clients5.google.com/translate_a/single?client=gtx&sl=auto&tl=en&dt=rm&q=\" + quote(word)\n",
        "  url = 'https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl=en&dt=t&dt=rm&q='+quote(word)+'&ie=UTF-8&oe=UTF-8'\n",
        "  headers = {\n",
        "      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'\n",
        "  }\n",
        "  requests.session().close()\n",
        "  \n",
        "  # time.sleep(chart)\n",
        "  trans = requests.get(url,headers=headers)\n",
        "  requests.session().close()\n",
        "      \n",
        "  try:\n",
        "      trans.json()\n",
        "  except json.decoder.JSONDecodeError:\n",
        "      print('ERRRRRRRRRRRRRRROR')\n",
        "      # os.kill(os.getpid(),9)\n",
        "      return False, False\n",
        "  try:\n",
        "      pronounciation = trans.json()[0][1][-1]\n",
        "  except IndexError:\n",
        "      pronounciation = trans.json()[0][0][1]\n",
        "  translation = trans.json()[0][0][0]\n",
        "  main = trans.json()[0][0][1]\n",
        "\n",
        "  # pronounciation,translation\n",
        "  if main==pronounciation:\n",
        "      # clear()\n",
        "      return translation,word\n",
        "  else:\n",
        "      # clear()\n",
        "      return translation,pronounciation\n",
        "  \n",
        "def translation_bouncer(line):\n",
        "  # line = 'Bunny is a rider'\n",
        "  i,character_length,last_execution_time = to_json({},'timer_circuit','read')\n",
        "  character_length+=len(line)\n",
        "  i+=1\n",
        "  \n",
        "  \n",
        "  # current_time = int(datetime.utcnow().timestamp())\n",
        "  # delayed = current_time-last_execution_time\n",
        "  ####TIME \n",
        "  # if character_length>maximum_allowed_character_length and character_length!=0 or i %number_of_requests == 0 and i!=0:\n",
        "  #   if int(datetime.utcnow().timestamp())-last_execution_time<100:\n",
        "  #     time.sleep(time_to_sleep)\n",
        "  #     if character_length>maximum_allowed_character_length:\n",
        "  #       character_length=0\n",
        "\n",
        "  j,k = fragile_translator_machine(line)\n",
        "  # current_time = int(datetime.utcnow().timestamp())\n",
        "  # to_json((i,character_length,int(datetime.utcnow().timestamp())),'timer_circuit','write')\n",
        "    # print('\\n')\n",
        "    # print(i)\n",
        "  if (j,k) == (False,False):\n",
        "    print(\"THE END IS HEREEEEEEEEEE!!! HALP :(\")\n",
        "    return False,False\n",
        "\n",
        "  sk = to_json({},'translation_database','read')\n",
        "  # sk={}\n",
        "  sk[line]={'main':line,\n",
        "            'pronounciation':k,\n",
        "            'translation':j}\n",
        "  to_json(sk,'translation_database','write')        \n",
        "  return sk[line]\n",
        "\n",
        "\n",
        "def translating(line):\n",
        "\n",
        "  sk = to_json({},'translation_database','read')\n",
        "  line = re.sub('‚Äò','\\'',line)\n",
        "  line = re.sub('‚Äú','\"',line)\n",
        "  line = re.sub('‚Äù','\"',line)\n",
        "  line = re.sub('‚Äô','\\'',line)\n",
        "  # sk={}\n",
        "  # sk = normalize_keys(s)\n",
        "  if line in empty_list or line == '\\u200b' or line =='\\u200b\\u200b':\n",
        "    return '',''\n",
        "  try:\n",
        "    j,k = sk[line]['translation'],sk[line]['pronounciation']\n",
        "    return zero_width_cleaner(j,1),zero_width_cleaner(k,1)\n",
        "  except KeyError:\n",
        "    # print('Translating',sep,line)\n",
        "    plop = translation_bouncer(line)\n",
        "    # clear()\n",
        "    return zero_width_cleaner(plop['translation'],1),zero_width_cleaner(plop['pronounciation'],1)\n",
        "# to_json({},'translation_database','read')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZTGQNgLIMqs"
      },
      "outputs": [],
      "source": [
        "def show_song_list(types):\n",
        "  # types = input('1: for SID, 2 for SLSD\\n')\n",
        "  clear()\n",
        "  if types in empty_list:\n",
        "    return 'Oka bai'\n",
        "  types = int(types)-1\n",
        "  l = []\n",
        "  typo = [sid,slsd] \n",
        "  print('Showing',typo[types]+'....')\n",
        "  s = to_json({},typo[types],'read')\n",
        "  for item in s:\n",
        "    l.append(done_dl[item]['file_name']+sep+item)\n",
        "  c = 0\n",
        "  for item in sorted(l):\n",
        "    c+=1\n",
        "    a,b = item.split(sep)\n",
        "    print(b,sep,a)\n",
        "  \n",
        "\n",
        "def get_key():\n",
        "  key = \"\".join(random.sample(st.ascii_lowercase+st.ascii_uppercase,16))\n",
        "  return key\n",
        "\n",
        "# get_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni1AB1gMLWtA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moQmsHp4Wl_G"
      },
      "outputs": [],
      "source": [
        "# re.search(r\"9999900001. (.*)?(.*) 9999900002.\",sp).group(1)\n",
        "def google_json_to_trans_pron(the_response_from_google):\n",
        "  sp = ''\n",
        "  count= 0\n",
        "  for items in the_response_from_google.json()[0]:\n",
        "    count+=1\n",
        "    for item in items:\n",
        "      \n",
        "      try:\n",
        "        if item.isdigit() is False or count==1:\n",
        "          \n",
        "          # print(item)\n",
        "\n",
        "          sp+=item+'\\n'\n",
        "      \n",
        "      except AttributeError:\n",
        "        continue\n",
        "  sp = sp.strip()\n",
        "  g_list = sp.split('\\n')\n",
        "  if len(g_list)%2==0:\n",
        "    trans = ''.join(g_list[0::2])\n",
        "    prons = ''.join(g_list[1::2])\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    trans = ''.join(g_list[:-1][0::2])\n",
        "    prons = g_list[-1]\n",
        "  \n",
        "  return trans,prons,g_list\n",
        "\n",
        "\n",
        "# google_json_to_trans_pron(the_response_from_google)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7IA65dfnxR8"
      },
      "outputs": [],
      "source": [
        "def play_another_video(s):\n",
        "  l = []\n",
        "  video_path = key_destination\n",
        "  count=0\n",
        "  if s in [\"\",'',\" \",' ']:\n",
        "    video_list = (os.listdir(video_path))\n",
        "  if s==1:\n",
        "    video_list = sorted(os.listdir(video_path))\n",
        "\n",
        "  for item in video_list:\n",
        "    count+=1\n",
        "    print(str(count)+sep+str(count-len(video_list))+'. ',item)\n",
        "\n",
        "    l.append(video_path+item)\n",
        "  time.sleep(1)\n",
        "  choice = input('\\nVideo to play: ')\n",
        "  if choice in [\"\",'',\" \",' ']:\n",
        "    clear()\n",
        "    return 'Oka bai, see ya later'\n",
        "  choice = int(choice)\n",
        "  clear()\n",
        "  print('Playing',l[choice-1].split(video_path)[-1][:-4]+'....'+'\\n')\n",
        "  if getfilesize(l[choice-1],2) > 21*1024**2:\n",
        "    if os.path.exists(placeholder_images) is False:\n",
        "      os.mkdir(placeholder_images)\n",
        "\n",
        "    new_vid =placeholder_images+l[choice-1].split(video_path)[-1]\n",
        "    com_file = os.path.splitext(new_vid)[0]+'_compressed.mp4'\n",
        "    if os.path.exists(com_file) is False:\n",
        "        \n",
        "      shutil.copy(l[choice-1],new_vid)\n",
        "      print(getfilesize(l[choice-1],1)+' video too big to display.')\n",
        "      print('Compressing...')\n",
        "      compress_video(new_vid,21*1024,True,'_compressed')\n",
        "      data_saved = format_size(getfilesize(l[choice-1],2)-getfilesize(com_file,2))\n",
        "      print('Compressed video is '+getfilesize(com_file,1)+' ['+data_saved+' saved]')\n",
        "      print('\\n')\n",
        "      os.remove(new_vid)\n",
        "    # time.sleep(2)\n",
        "    clear()\n",
        "    print('Playing',l[choice-1].split(video_path)[-1][:-4]+'....'+'\\n')\n",
        "    time.sleep(2)\n",
        "    display(Video(com_file,embed=True))\n",
        "  else:\n",
        "    display(Video(l[choice-1],embed=True))\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "def play_audio(music):\n",
        "  index = ''\n",
        "  done_dl = update_dl()\n",
        "  sd = get_sd()\n",
        "  clear()\n",
        "  lk = []\n",
        "  while lk==[]:\n",
        "    word = input('The song contains? ')\n",
        "    if word not in empty_list:\n",
        "      for item in sd:\n",
        "        if norm(word.lower().strip()) in norm(sd[item]['file_name'].lower().strip()):\n",
        "          lk.append(sd[item]['file_name']+separator+\"{\"+item+\"}\")\n",
        "    else:\n",
        "      lk=[]\n",
        "  lk = sorted(lk)\n",
        "  c= 0 \n",
        "  print('\\n')\n",
        "  for item in lk:\n",
        "    c+=1\n",
        "    print(str(c)+'. '+item)\n",
        "\n",
        "  choice = input('\\nChoose index of song: [x: ignore, ENTER: first one]\\n')\n",
        "  if choice in ['x','X']:\n",
        "    clear()\n",
        "    return 'ok bai ;P'\n",
        "  else:\n",
        "    if choice in empty_list:\n",
        "      clear()\n",
        "      choice = 0\n",
        "      index = lk[choice].split(separator)[-1].strip('{}')\n",
        "      \n",
        "      if music in empty_list:\n",
        "        print('Playing '+done_dl[index]['file_name']+'....'+'\\n'+'Index:',index+'\\n')\n",
        "        time.sleep(2)\n",
        "        return Audio(done_dl[index]['location'],embed=True,autoplay=True)\n",
        "      else:\n",
        "        print('Showing data for '+done_dl[index]['file_name']+'....')\n",
        "        return done_dl[index]\n",
        "\n",
        "    else:\n",
        "      clear()\n",
        "      choice = int(choice)-1\n",
        "      index = lk[choice].split(separator)[-1].strip('{}')\n",
        "      if music in empty_list:\n",
        "        print('Playing '+done_dl[index]['file_name']+'....'+'\\n'+'Index:',index+'\\n')\n",
        "        time.sleep(2)\n",
        "        return Audio(done_dl[index]['location'],embed=True,autoplay=True)\n",
        "      else:\n",
        "        print('Showing data for '+done_dl[index]['file_name']+'....')\n",
        "        return done_dl[index]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def update_dl():\n",
        "  music = '/content/drive/MyDrive/essentials/My_Music/'\n",
        "  \n",
        "  done_dl = {}\n",
        "  \n",
        "  count = 0\n",
        "  for folders in os.listdir(music):\n",
        "    for files in os.listdir(music+folders):\n",
        "      if files.endswith('.mp3'):\n",
        "        count +=1\n",
        "        num,name = files.split('}')\n",
        "        \n",
        "        num = int(num.strip('{').strip())\n",
        "        name = name.split('.mp3')[0].strip()\n",
        "        loc = music+folders+'/'+files\n",
        "        \n",
        "        # if count%10==0:\n",
        "        #   clear()\n",
        "\n",
        "        # if str(num) in done_dl_keys:\n",
        "        #   continue\n",
        "        # print(num,name)\n",
        "        \n",
        "        # print(count+1,num,name,'added')\n",
        "        \n",
        "        done_dl[num] = {'file_index': num,\n",
        "                        'location':loc,\n",
        "                        'file_name':name}\n",
        "\n",
        "  to_json(done_dl,'downloaded_music_database','write')\n",
        "\n",
        "  return to_json({},'downloaded_music_database','read')\n",
        "# play_audio('')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFh1yKpkSKkR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def prelude_to_translate(lyrics):\n",
        "  count=0\n",
        "  w=''\n",
        "  for item in lyrics.split('\\n'):\n",
        "    if item not in empty_list:\n",
        "      count+=1\n",
        "      each_line= '.'+str(69213000+count)+'. '+item+' '\n",
        "      # print(each_line)\n",
        "      w+=each_line\n",
        "  w=w.strip(' ')\n",
        "  return  w\n",
        "\n",
        "\n",
        "def remover(w):\n",
        "  l = {}\n",
        "  w = w.strip('. ')\n",
        "  for item in w.split('69213'):\n",
        "    if item not in empty_list and item not in ['.']:\n",
        "      key = item[0:4]\n",
        "      line = item[4:].strip(' .')\n",
        "      line = re.sub(r\"(\\d)+(.*)\",\"\",line)\n",
        "      \n",
        "      l[key]=line\n",
        "      \n",
        "  for item in w.split('.69213'):\n",
        "    if item not in empty_list:\n",
        "      # if item in w.split('.69213'):\n",
        "      key = item[0:4]\n",
        "      # if key not in l.keys():\n",
        "      line = item[4:].strip(' .')\n",
        "      line = re.sub(r\"(\\d)+(.*)\",\"\",line)\n",
        "      l[key]=line\n",
        "\n",
        "  for item in list(l.keys()):\n",
        "    if item.endswith('.') is False:\n",
        "      l.pop(item)\n",
        "  # l.pop('')\n",
        "  return l\n",
        "\n",
        "def google_translator(entire_fucking_thing):\n",
        "  word = entire_fucking_thing\n",
        "  url = 'https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl=en&dt=t&dt=rm&q='+quote(word)+'&ie=UTF-8&oe=UTF-8'\n",
        "  headers = {\n",
        "      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'\n",
        "  }\n",
        "  requests.session().close()\n",
        "\n",
        "  # time.sleep(chart)\n",
        "  trans = requests.get(url,headers=headers)\n",
        "  requests.session().close()\n",
        "      \n",
        "  try:\n",
        "      trans.json()\n",
        "  except json.decoder.JSONDecodeError:\n",
        "      print('ERRRRRRRRRRRRRRROR')\n",
        "      # os.kill(os.getpid(),9)\n",
        "      return False, False\n",
        "  \n",
        "  return trans\n",
        "\n",
        "done_dl = update_dl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXEL9T2ClEVK"
      },
      "outputs": [],
      "source": [
        "def lyrics_translator(lyrics):\n",
        "  line = re.sub('‚Äò','\\'',lyrics)\n",
        "  line = re.sub('‚Äú','\"',line)\n",
        "  line = re.sub('‚Äù','\"',line)\n",
        "  line = re.sub('‚Äô','\\'',line)\n",
        "\n",
        "  lyrics1 = prelude_to_translate(line)\n",
        "  the_response_from_google =  google_translator(lyrics1)\n",
        "  trans,pron,the_g_list = google_json_to_trans_pron(the_response_from_google)\n",
        "  main, trans, pron = remover(lyrics1),remover(trans),remover(pron)\n",
        "  sk = to_json({},'translation_database','read')\n",
        "  # sk={}\n",
        "  jk = {}\n",
        "  for i in range(len(main)):\n",
        "    key = str(i+1).zfill(3)+'.'\n",
        "    \n",
        "    m = main[key]\n",
        "    p = pron[key]\n",
        "    try:\n",
        "      t = trans[key]\n",
        "    except KeyError:\n",
        "      trgf = google_translator(m)\n",
        "      t,p,g_l = google_json_to_trans_pron(trgf)\n",
        "      # t,p = zero_width_cleaner(t,1),zero_width_cleaner(p,1)\n",
        "      t=t.rstrip('.')\n",
        "    # if t in empty_list or len(t)<len(p)*.8 or len(t)>len(p)*1.2:\n",
        "    if t in empty_list:\n",
        "\n",
        "      print(str(i+1)+'/'+str(len(main)))\n",
        "      print('\\n')\n",
        "      print('main',sep,m)\n",
        "      print('trans',sep,t)\n",
        "      print('pron',sep,p)\n",
        "      print('\\n\\nShould I re-translate this??')\n",
        "      time.sleep(1)\n",
        "      selection = input('Ignore: Enter, \"43256\": to re-translate\\n')\n",
        "      if selection not in empty_list and selection == '43256':\n",
        "        trgf = google_translator(m)\n",
        "        t,p,g_l = google_json_to_trans_pron(trgf)\n",
        "        t,p = t,p\n",
        "      clear()\n",
        "    \n",
        "    jk[m]={'main':m,\n",
        "          'translation':t.rstrip('.'),\n",
        "          'pronounciation':p}\n",
        "    \n",
        "    sk[m]={'main':m,\n",
        "          'translation':t.rstrip('.'),\n",
        "          'pronounciation':p}\n",
        "  display(jk)\n",
        "  time.sleep(2)\n",
        "  save_it = input('\\n\\nWOULD YOU SAVE THIS TRANSLATION??\\nEnter \"815632\": to confirm:\\n')\n",
        "  if save_it == '815632':\n",
        "    to_json(sk,'translation_database','write')\n",
        "    \n",
        "  else:\n",
        "    clear()\n",
        "    \n",
        "    print('THE SET VARIABLE CONTAINS THE RESPONSE FROM GOOGLE\\n')\n",
        "  return the_response_from_google,the_g_list\n",
        "\n",
        "def lyrics_from_slsd(end_string):\n",
        "  if end_string in empty_list:\n",
        "    end_string = '\\n'\n",
        "  w=''\n",
        "  for item in to_json({},slsd,'read')[index].split('\\n'):\n",
        "    c,d = item.split(']')\n",
        "    if d not in [\"\\u200b\"] and item not in empty_list:\n",
        "      \n",
        "      w+=d+end_string\n",
        "\n",
        "  return w.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jmoZJ3m109i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def adds_to_font_database(line):\n",
        "  k = to_json({},fd,'read')\n",
        "  w=''\n",
        "  for word in line.split():\n",
        "    try:\n",
        "      if k[word] != empty_list:\n",
        "        w+=word+' '\n",
        "        continue\n",
        "    except KeyError:\n",
        "      a= fontained(word)\n",
        "      for i in range(len(a)):\n",
        "        w+=a[i]['word']+' '\n",
        "        k[a[i]['word']]=a[i]['font']\n",
        "      to_json(k,fd,'write')\n",
        "      clear()\n",
        "  return w.strip()\n",
        "\n",
        "# k = to_json({},fd,'read')\n",
        "# k = adds_to_font_database(line)\n",
        "\n",
        "def fontaine(line):\n",
        "  line = adds_to_font_database(line)\n",
        "  k = to_json({},fd,'read')\n",
        "  w= ''\n",
        "  l=[]\n",
        "  font = default\n",
        "  for word in line.split():\n",
        "    if k[word]==font:\n",
        "      w+=word+' '\n",
        "    else:\n",
        "      if w not in empty_list:\n",
        "        l.append({'word':w.strip(),'font':font})\n",
        "      w=word+' '\n",
        "      font = k[word]\n",
        "  l.append({'word':w.strip(),'font':font})\n",
        "  return l\n",
        "\n",
        "  \n",
        "# line = \n",
        "# strp = \"sofuhn ŸäŸÑÿß ÿ≠ÿ®Ÿä ŸäŸÑÿß jjjjjjjj ŸÖÿ¥ ÿ≠ŸÑŸà üòú ÿ™ÿ¨ÿ±ÿ≠ŸÜŸä ÿ®ŸáŸàÿßŸÉ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ú‡¶æ‡¶®‡¶æ‡¶≤‡¶æ‡ßü Áà± bts ‡¶π‡¶æ‡¶∏‡¶ø‡¶Æ‡ßÅ‡¶ñ bts biot   \"\n",
        "# strp = 'Áà±? sofuhn'\n",
        "# strp = 'ŸäŸÑÿß ÿ≠ÿ®Ÿä ŸäŸÑÿß jjjjjjjj'\n",
        "\n",
        "def fontained(line):\n",
        "  \n",
        "  \n",
        "\n",
        "  fon1 = default\n",
        "  # regular_files = font_file_list()\n",
        "  regular_files.insert(0,default)\n",
        "  # regular_files = font_files\n",
        "  \n",
        "\n",
        "  w=''\n",
        "  l = []\n",
        "  for word in line.split():\n",
        "    # w+='\\u200b'\n",
        "    for char in word:\n",
        "      # print(allowed_punct)\n",
        "      if char in [\"\\u200d\"]:\n",
        "        l.append({'letter':char,'font':fon1})\n",
        "        continue\n",
        "\n",
        "      if char in ['-',',','.']:\n",
        "        l.append({'letter':char,'font':fon1})\n",
        "\n",
        "        continue\n",
        "      if char in allowed_punct:\n",
        "        # print(char,allowed_punct)\n",
        "          # l.append({'letter':char,'font':fon1})\n",
        "        # print(char)\n",
        "        \n",
        "        l.append({'letter':char,'font':default})\n",
        "        continue\n",
        "      if check_font(font_path+fon1,char):\n",
        "        if check_font(font_path+default,char):\n",
        "          fon1 = default\n",
        "          # w=char\n",
        "          l.append({'letter':char,'font':fon1})\n",
        "        else:\n",
        "          l.append({'letter':char,'font':fon1})\n",
        "          \n",
        "\n",
        "      else:\n",
        "        for files in regular_files:\n",
        "          if check_font(font_path+files,char):\n",
        "            fon1 = files\n",
        "            regular_files.insert(1,files)\n",
        "            break\n",
        "        l.append({'letter':char,'font':fon1})\n",
        "    l.append({'letter':' ','font':fon1})\n",
        "  # print(l)\n",
        "  p = []\n",
        "  w=''\n",
        "  font = default\n",
        "  for i in range(len(l)):\n",
        "\n",
        "    if l[i]['font']==font:\n",
        "      w+=l[i]['letter']\n",
        "    else:\n",
        "      if w not in empty_list:\n",
        "        p.append({'word':w.strip(),'font':font})\n",
        "      w=l[i]['letter']\n",
        "\n",
        "      font = l[i]['font']\n",
        "  p.append({'word':w.strip(),'font':font})\n",
        "  return p\n",
        "\n",
        "\n",
        "def font_file_list():\n",
        "  # frequent = ['NotoSansMonoCJ','NotoNaksh','NotoSerifBengali','NotoSans-Regular']\n",
        "  regular_files = []\n",
        "  # for files in os.listdir(font_path):\n",
        "  #   for item in frequent:\n",
        "  #     if files.startswith(item):\n",
        "  #       regular_files.append(files)\n",
        "\n",
        "  for files in os.listdir(font_path):\n",
        "    if files.startswith('Noto'):\n",
        "      regular_files.append(files)\n",
        "  return regular_files \n",
        "\n",
        "def check_font(font,character):\n",
        "  font = ttfont(font)\n",
        "  for table in font['cmap'].tables:\n",
        "    if ord(character) in table.cmap.keys():\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "regular_files = font_file_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkFtUMgFlKpG"
      },
      "outputs": [],
      "source": [
        "############# VIDEO COMPRESSOR FROM GITHUB\n",
        "import ffmpeg\n",
        "def compress_video(video_full_path, size_upper_bound, two_pass=True, filename_suffix='1'):\n",
        "    \"\"\"\n",
        "    Compress video file to max-supported size.\n",
        "    :param video_full_path: the video you want to compress.\n",
        "    :param size_upper_bound: Max video size in KB.\n",
        "    :param two_pass: Set to True to enable two-pass calculation.\n",
        "    :param filename_suffix: Add a suffix for new video.\n",
        "    :return: out_put_name or error\n",
        "    \"\"\"\n",
        "    filename, extension = os.path.splitext(video_full_path)\n",
        "    extension = '.mp4'\n",
        "    output_file_name = filename + filename_suffix + extension\n",
        "\n",
        "    total_bitrate_lower_bound = 11000\n",
        "    min_audio_bitrate = 32000\n",
        "    max_audio_bitrate = 256000\n",
        "    min_video_bitrate = 100000\n",
        "\n",
        "    try:\n",
        "        # Bitrate reference: https://en.wikipedia.org/wiki/Bit_rate#Encoding_bit_rate\n",
        "        probe = ffmpeg.probe(video_full_path)\n",
        "        # Video duration, in s.\n",
        "        duration = float(probe['format']['duration'])\n",
        "        # Audio bitrate, in bps.\n",
        "        audio_bitrate = float(next((s for s in probe['streams'] if s['codec_type'] == 'audio'), None)['bit_rate'])\n",
        "        # Target total bitrate, in bps.\n",
        "        target_total_bitrate = (size_upper_bound * 1024 * 8) / (1.073741824 * duration)\n",
        "        if target_total_bitrate < total_bitrate_lower_bound:\n",
        "            print('Bitrate is extremely low! Stop compress!')\n",
        "            return False\n",
        "\n",
        "        # Best min size, in kB.\n",
        "        best_min_size = (min_audio_bitrate + min_video_bitrate) * (1.073741824 * duration) / (8 * 1024)\n",
        "        if size_upper_bound < best_min_size:\n",
        "            print('Quality not good! Recommended minimum size:', '{:,}'.format(int(best_min_size)), 'KB.')\n",
        "            # return False\n",
        "\n",
        "        # Target audio bitrate, in bps.\n",
        "        audio_bitrate = audio_bitrate\n",
        "\n",
        "        # target audio bitrate, in bps\n",
        "        if 10 * audio_bitrate > target_total_bitrate:\n",
        "            audio_bitrate = target_total_bitrate / 10\n",
        "            if audio_bitrate < min_audio_bitrate < target_total_bitrate:\n",
        "                audio_bitrate = min_audio_bitrate\n",
        "            elif audio_bitrate > max_audio_bitrate:\n",
        "                audio_bitrate = max_audio_bitrate\n",
        "\n",
        "        # Target video bitrate, in bps.\n",
        "        video_bitrate = target_total_bitrate - audio_bitrate\n",
        "        if video_bitrate < 1000:\n",
        "            print('Bitrate {} is extremely low! Stop compress.'.format(video_bitrate))\n",
        "            return False\n",
        "\n",
        "        i = ffmpeg.input(video_full_path)\n",
        "        if two_pass:\n",
        "            ffmpeg.output(i, '/dev/null' if os.path.exists('/dev/null') else 'NUL',\n",
        "                          **{'c:v': 'libx264', 'b:v': video_bitrate, 'pass': 1, 'f': 'mp4'}\n",
        "                          ).overwrite_output().run()\n",
        "            ffmpeg.output(i, output_file_name,\n",
        "                          **{'c:v': 'libx264', 'b:v': video_bitrate, 'pass': 2, 'c:a': 'aac', 'b:a': audio_bitrate}\n",
        "                          ).overwrite_output().run()\n",
        "        else:\n",
        "            ffmpeg.output(i, output_file_name,\n",
        "                          **{'c:v': 'libx264', 'b:v': video_bitrate, 'c:a': 'aac', 'b:a': audio_bitrate}\n",
        "                          ).overwrite_output().run()\n",
        "\n",
        "        if os.path.getsize(output_file_name) <= size_upper_bound * 1024:\n",
        "            return output_file_name\n",
        "        elif os.path.getsize(output_file_name) < os.path.getsize(video_full_path):  # Do it again\n",
        "            return compress_video(output_file_name, size_upper_bound)\n",
        "        else:\n",
        "            return False\n",
        "    except FileNotFoundError as e:\n",
        "        print('You do not have ffmpeg installed!', e)\n",
        "        print('You can install ffmpeg by reading https://github.com/kkroening/ffmpeg-python/issues/251')\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "509fUo7v0GTr"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# def chinese_and_japanese(line):\n",
        "  \n",
        "#   # line = ''.join(line.split())\n",
        "#   j,k = translating(line)\n",
        "  \n",
        "#   if (j,k)==(False,False):\n",
        "#     j,k = timer_for_google_translate(line)\n",
        "\n",
        "#   count=len(k.split())\n",
        "#   l = norm(k).strip().lower().split()\n",
        "#   k,count\n",
        "  \n",
        "#   w =''\n",
        "#   f=[]\n",
        "#   # while len(f)<count:\n",
        "#   #   f=[]\n",
        "#   #   if w!='':\n",
        "#   #     line = ' '.join(f[::-1])\n",
        "#   #     j,k = translating(line)\n",
        "#   #     l = norm(k).strip().lower().split()\n",
        "#   #     w=''\n",
        "#   for char in line[::-1]:  \n",
        "#     w=char+w\n",
        "#     a,b = translating(w)\n",
        "#     # while (a,b)==(False,False):\n",
        "#     #   a,b = translating(w)   \n",
        "\n",
        "#     if (a,b)==(False,False):\n",
        "#       a,b = timer_for_google_translate(w)\n",
        "#     b = norm(b).strip().lower()    \n",
        "\n",
        "#     # print(w,sep,b,sep,l,f[::-1])             #uncomment this to debug\n",
        "#     try:\n",
        "#       if ''.join(str(b)[2:-1].split()).startswith(str(l[-1])[2:-1]) or ''.join(str(b)[2:-1].split()).startswith(str(l[-2])[2:-1]):\n",
        "#       # if ''.join(str(b)[2:-1].split()).startswith(str(l[-1])[2:-1]):\n",
        "#         l.pop()\n",
        "#         f.append(w.strip())\n",
        "#         w=''\n",
        "#         continue\n",
        "#       if b.split()[-1] == l[-1] or norm(''.join(str(b)[2:-1].split())) ==l[-1] or len(b.split()[-1]) == len(l[-1]) and b[0]==l[-1][0]:\n",
        "        \n",
        "#         l.pop()    \n",
        "\n",
        "        \n",
        "#         # print('\\ninside',w)\n",
        "#         # print('w',sep,w,sep,len(w.split()))\n",
        "#         # print('b',sep,b,sep,len(b.split()))\n",
        "#         # print('\\n')\n",
        "        \n",
        "        \n",
        "#         if len(b.split())==2:\n",
        "#           # if len(w.split())>1:\n",
        "#           #   f.append(w.split()[-1].strip())\n",
        "#           #   w=w.split()[0]\n",
        "        \n",
        "#           if len(w.split())==1:\n",
        "#             f.append(w[1:].strip())\n",
        "#             w=char\n",
        "#             continue\n",
        "\n",
        "          \n",
        "      \n",
        "#         elif len(b.split())==1:\n",
        "#           if len(w.split())==1:\n",
        "#             # w=''.join(w.split())\n",
        "#             f.append(w.strip())\n",
        "#             w=''\n",
        "#             continue\n",
        "#           elif len(w.split())==2:\n",
        "#             w = ''.join(w.split())\n",
        "#             f.append(w.strip())\n",
        "#             w=''\n",
        "#             continue\n",
        "            \n",
        "        \n",
        "      \n",
        "        \n",
        "#           # if len(b.split())==1:\n",
        "#           #   f.append(w.strip())\n",
        "#           #   w=''\n",
        "\n",
        "#       # if b==l[-1]:\n",
        "#       #   l.pop()\n",
        "#       #   # print(w,sep,b,sep,l)\n",
        "#       #   f.append(w.strip())\n",
        "#       #   w=''\n",
        "      \n",
        "      \n",
        "#     except IndexError:\n",
        "#       continue\n",
        "#   f.append(w)\n",
        "\n",
        "#   return ' '.join(f[::-1])\n",
        "\n",
        "# line = '‰∏çÂêåÁöÑÊó∂Èó¥ÂíåÊïÖ‰∫ãËÆ©ÊàëËÉΩÈ©æÈ©≠ÊâÄÊúâ‰∏çÂè™ÊòØËøô‰∏™‰º¥Â•è'\n",
        "def cage(line):\n",
        "  # line = input()\n",
        "\n",
        "  j,k = translating(line)\n",
        "  while (j,k)==(False,False):\n",
        "    j,k = translating(line)\n",
        "  line = zero_width_cleaner(line,'')\n",
        "  words = fontaine(line)\n",
        "  width = len(k.split())\n",
        "  \n",
        "  f = []\n",
        "  for item in words:\n",
        "    # print(item['word'],sep,item['font'])\n",
        "    if item['font'] != default:\n",
        "      \n",
        "      f.append(chinese_and_japanese(item['word']))\n",
        "    else:\n",
        "      f.append(item['word'])\n",
        "  w=''\n",
        "  for i in range(len(f)):\n",
        "    w+=f[i].strip()\n",
        "    # print(w)\n",
        "    \n",
        "    if i <len(f):\n",
        "      try:\n",
        "        # print(f[i])\n",
        "        if f[i+1][0] not in non_space_punct and f[i+1][0] not in right_side:\n",
        "          if f[i][-1] not in left_side:\n",
        "            w+=' '\n",
        "        else:\n",
        "          continue\n",
        "      except IndexError:\n",
        "        break\n",
        "  # print(w)\n",
        "  # display(' '.join(f))\n",
        "  # print(k)\n",
        "  return '\\n'+w.strip()\n",
        "\n",
        "\n",
        "def bird_cage(line,types):\n",
        "  w=''\n",
        "  for lines in line.split('\\n'):\n",
        "    if lines not in empty_list:\n",
        "      \n",
        "      w+=cage(lines)\n",
        "\n",
        "  return w\n",
        "\n",
        "def lyrics_word_splitter(split_lyrics):\n",
        "\n",
        "  s = to_json({},sid,'read')\n",
        "  if split_lyrics == 1:\n",
        "  # print(s[index]['lyrics'])\n",
        "    new = s[index]['lyrics']\n",
        "    new = bird_cage(new,'')\n",
        "  # print('\\n\\n')\n",
        "  s[index]['lyrics']=new\n",
        "  # s[index]['lyrics']\n",
        "  to_json(s,sid,'write')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7iDKpf_6tlv"
      },
      "outputs": [],
      "source": [
        "def slsd_splitter_after_lyrics_is_split():\n",
        "  t = to_json({},slsd,'read')\n",
        "  \n",
        "  w=''\n",
        "  for item in t[index].split('\\n'):\n",
        "    \n",
        "    time,line = item.split(']')\n",
        "    if line not in ['\\u200b'] and line not in empty_list:\n",
        "      line = bird_cage(line,'').strip('\\n')\n",
        "    else:\n",
        "      line = '\\u200b'\n",
        "    w+=time+']'+line+'\\n'\n",
        "  w=w.strip()\n",
        "  t[index]=w\n",
        "  \n",
        "  to_json(t,slsd,'write')\n",
        "\n",
        "# slsd_splitter_after_lyrics_is_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsjfRJdM-gaS"
      },
      "outputs": [],
      "source": [
        "# len(to_json({},'translation_database','read'))\n",
        "# lyrics_translator(input())\n",
        "done_dl= update_dl()\n",
        "g=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ixJth3rGNOr"
      },
      "outputs": [],
      "source": [
        "def matrix(string,alpha,color_dictionary):\n",
        "  # w=''\n",
        "  l = []\n",
        "  string  = string.split()\n",
        "  for words in string:\n",
        "    if words not in empty_list:\n",
        "      l.append(words)\n",
        "  string = l\n",
        "  if len(string) <= res:\n",
        "    \n",
        "    mult = math.floor(res/len(string))\n",
        "  else:\n",
        "    # res1 = len(string)\n",
        "    mult = 1\n",
        "\n",
        "  pixel = mult\n",
        "  width = height = len(string)*mult\n",
        "  if alpha == 1:\n",
        "    main_image = Image.new('RGBA',[width,height],(0,0,0,0))\n",
        "  else:\n",
        "    main_image = Image.new('RGBA',[width,height],(0,0,0))\n",
        "\n",
        "  margin=offset = 0\n",
        "\n",
        "  for word_a in string:\n",
        "    for word_b in string:\n",
        "      if strips_words(word_a.strip().lower(),0,1)==strips_words(word_b.strip().lower(),0,1) and word_a not in p1 and word_a not in p2:\n",
        "        \n",
        "        main_image.paste(Image.new('RGB',[pixel,pixel],color_dictionary[strips_words(word_a.strip().lower(),0,1)]),(margin,offset))\n",
        "        offset+=pixel\n",
        "      else:\n",
        "        offset+=pixel\n",
        "    margin+=pixel\n",
        "    offset=0\n",
        "  # print(lyr_data[k])\n",
        "  return main_image.resize([res,res],reducing_gap=4)\n",
        "\n",
        "def making_pattern(image,pattern,res):\n",
        "  if pattern == 'none':\n",
        "    return image\n",
        "  h = int(image.size[0]*2)\n",
        "  new = Image.new('RGBA',[h,h],(0,0,0,0))\n",
        "\n",
        "  if pattern == 'box':\n",
        "    c = 0\n",
        "    d = 270\n",
        "    a = 90\n",
        "    b = 180\n",
        "\n",
        "  if pattern == 'x':\n",
        "      \n",
        "    a = 0\n",
        "    b = 270\n",
        "    c = 90\n",
        "    d = 180\n",
        "    # a,b,c,d = 180,90,270,0\n",
        "\n",
        "  new.paste(image.rotate(a),(0,0))\n",
        "  new.paste(image.rotate(b),(int(h/2),0))\n",
        "  new.paste(image.rotate(c),(0,int(h/2)))\n",
        "  new.paste(image.rotate(d),(int(h/2),int(h/2)))\n",
        "  new = new.resize([res,res],reducing_gap=3)\n",
        "  return new\n",
        "\n",
        "\n",
        "def ran_col():\n",
        "  a=b=c=0\n",
        "  \n",
        "  d = 0+63\n",
        "  e = 255\n",
        "  thres = int((e-d)/10)\n",
        "  while abs(a-b)<thres and abs(a-c)<thres and abs(b-c)<thres:\n",
        "    a,b,c = random.randint(d,e),random.randint(d,e),random.randint(d,e)\n",
        "  # print(a,b,c)\n",
        "  return a,b,c\n",
        "\n",
        "\n",
        "\n",
        "def colors(string):\n",
        "  \n",
        "  color_dictionary = {}\n",
        "  s = strips_words(string,0,1)\n",
        "  c= {}\n",
        "  for words in s.split():\n",
        "    if words not in empty_list:\n",
        "      color_dictionary[ran_col()]=words\n",
        "  for item in color_dictionary:\n",
        "    c[color_dictionary[item]]=item\n",
        "    \n",
        "    \n",
        "  return c\n",
        "\n",
        "\n",
        "def strips_words(string,split,is_this_lyrics):\n",
        "  if string in lst:\n",
        "    return string\n",
        "  a = zero_width_cleaner(string,is_this_lyrics)\n",
        "  \n",
        "  a = re.sub('\\n',' ',a).strip()\n",
        "  a = re.sub(\"  \",\" \",a)\n",
        "  a = a.lower()\n",
        "  \n",
        "  a = re.sub(r\"(?<!\\w)\\'|\\'(?!\\w)\",'',a) # deletes trailing and preceeding apostrophe\n",
        "  a = re.sub(r\"-(?<!\\w)\\-|\\-(?!\\w)-\",'',a) \n",
        "  a = re.sub(r\"(?<!\\w)\\‚Äô|\\‚Äô(?!\\w)\",'',a) # deletes trailing and preceeding apostrophe\n",
        "  \n",
        "  a = re.sub(r\"(?<!\\w)\\‚Äú|\\‚Äú(?!\\w)\",'',a)\n",
        "  a = re.sub(r\"(?<!\\w)\\‚Äù|\\‚Äù(?!\\w)\",'',a)\n",
        "  a = re.sub(r\"(?<!\\w)\\‚Äò|\\‚Äò(?!\\w)\",'',a) # deletes trailing and preceeding apostrophe\n",
        "  # a = re.sub(r\"[^\\S]?(\\(.*?\\))[^\\S]?\", r\" \\1 \", a).strip() ## puts space before parenthesis\n",
        "  if is_this_lyrics not in empty_list:\n",
        "    a = a.translate(str.maketrans(\"\",\"\",p1))\n",
        "\n",
        "  \n",
        "  # a= re.sub(r'-(?!\\w)|(?<!\\w)-','',a)\n",
        "  \n",
        "\n",
        "\n",
        "  if split==1:\n",
        "    a = a.split()\n",
        "\n",
        "  return a\n",
        "\n",
        "\n",
        "def lyrics_solver(lyrics):\n",
        "  w = ''\n",
        "  j = fontaine(lyrics)\n",
        "  for i in range(len(j)):\n",
        "    \n",
        "    # w+=j[i]['word']+'\\n'\n",
        "\n",
        "    w+=j[i]['word']\n",
        "    try:\n",
        "      if j[i+1]['word'][0] not in non_space_punct and j[i+1]['word'][0] not in right_side:\n",
        "        if j[i]['word'][-1] not in left_side:\n",
        "          w+=' '\n",
        "    except IndexError:\n",
        "      break\n",
        "\n",
        "  return w\n",
        "\n",
        "\n",
        "\n",
        "def lyr_data_to_lyrics():\n",
        "  w=''\n",
        "  lyr_data = to_json({},slsd,'read')[index].split('\\n')\n",
        "  for i in lyr_data:\n",
        "    c,d = i.split(']')\n",
        "    if d not in [\"\\u200b\"]:\n",
        "      # p = lyr_data[i].strip()+'\\n'\n",
        "      w += lyrics_solver(d)+'\\n'\n",
        "  return w.strip()\n",
        "# lyr_data_to_lyrics()\n",
        "# lyr_data_to_lyrics()\n",
        "\n",
        "\n",
        "# lyr_data_to_lyrics()\n",
        "\n",
        "def checktd():\n",
        "  return len(to_json({},td,'read'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xtxdV8kyaUC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sid_data_to_lyrics():\n",
        "  w=''\n",
        "  lyr_data = to_json({},sid,'read')[index]['lyrics'].split('\\n')\n",
        "  for i in lyr_data:\n",
        "    # c,d = i.split(']')\n",
        "    d= i\n",
        "    if d not in [\"\\u200b\"]:\n",
        "      # p = lyr_data[i].strip()+'\\n'\n",
        "      w += lyrics_solver(d)+'\\n'\n",
        "  return w.strip()\n",
        "\n",
        "# print(sid_data_to_lyrics())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chinese_and_japanese(line):\n",
        "    # line='„ÅÇ„Å™„Åê„Çâ „Åê „Çâ „Åó „ÅÆ Ê∏¶ „ÅÆ ‰∏≠'\n",
        "  # line ='Êâã„Çí‰º∏„Å∞„Åó„Å¶„Åï„ÅÇ„Åï„ÅÇ„Åï„ÅÇÊ≠©„Åç„Å†„Åó„Å¶„Å∑„Åè„Å∑„Åè„Å∑„Åè'\n",
        "  # line = '‰∏çÂêåÁöÑÊó∂Èó¥ÂíåÊïÖ‰∫ãËÆ©ÊàëËÉΩÈ©æÈ©≠ÊâÄÊúâ‰∏çÂè™ÊòØËøô‰∏™‰º¥Â•è'\n",
        "  # line = 'Èóá„Å´ËêΩ„Å°„Å¶ËêΩ„Å°„Å¶ËêΩ„Å°„Å¶„ÇÜ„Åè Èúß „ÅÆ‰∏≠ „Å´ Áîü„Åæ„Çå„Å¶'\n",
        "  # line = '„Åç„Åø „ÇÇ ‰ª≤Èñì „Å´ÂÖ• „Çå „Åü„Åí„Çã'\n",
        "  # line = '„Åì„Çå„Åã„Çâ„ÇÇ„Åì„Çå„Åã„Çâ„ÇÇ„Åº„Åè„Åå„Åö„Å£„Å®„ÅÑ„Å°„Å∞„Çì„Å™„Çì„Å†'\n",
        "  # line = '„Åù„Å£„Å®„Åù„Å£„Å®„Å™„Çì„Å´„ÇÇÁü•„Çâ„Å™„ÅÑ„Åæ„Çì„Åæ'\n",
        "  # line= '„Åù„Å£„Å® „Åù„Å£„Å® „Å™„Çì„Å´„ÇÇ Áü•„Çâ„Å™„ÅÑ „Åæ„Çì„Åæ'\n",
        "  # line='ÂÖ®ÈÉ®Áü•„Å£„Å¶„Çã„Åã„Çâ'\n",
        "  # line= '‰∫å‰∏Ä „Çº„É≠'\n",
        "  # line='„ÅÇ„Å™„Åê„Çâ „Åê „Çâ „Åó „ÅÆ Ê∏¶ „ÅÆ ‰∏≠'\n",
        "  # line = '„Åç„Åø „Å®ÂÉï„Å® „ÅØ „ÅÑ „Å§ „Åæ„Åß „ÇÇ'\n",
        "  # line = 'ÊúâË±° „Å´ÁÑ° Ë±° „ÅÆ È≠ëÈ≠ÖÈ≠çÈ≠é „Åï„ÅÇ Â¢ìÂ†¥ „Åß Ë∏ä„Çä„Åæ„Åó„Çá„ÅÜ'\n",
        "  # line = 'ÊÄ®Âøµ „ÅåÊÄ® Âøµ „ÅåÊÄ® Âøµ „Åå ÈôΩÊ∞ó„Åß'\n",
        "  # line = 'ÊúâË±° „Å´ÁÑ° Ë±° „ÅÆ È≠ëÈ≠ÖÈ≠çÈ≠é „Åï„ÅÇ Â¢ìÂ†¥ „Åß Ë∏ä„Çä„Åæ„Åó„Çá„ÅÜ „ÉÅ„É£„ÉÅ„É£„Ç¶„ÉÉ'\n",
        "  # line = '„Ç≠„É©„Ç§„Å™Ëá™ÂàÜ„Å´Âàë‰∫ãÁΩ∞„Åê„Çã„Åê „Çã ÊÄù ËÄÉ „ÅÆËß£ Êîæ'\n",
        "  # line = '„Åç„Åø „ÇÇ ‰ª≤Èñì „Å´ÂÖ• „Çå „Åü„Åí„Çã'\n",
        "  # line='„Å®„ÇäÊÜë„ÅÑ„Åü„Å®„Çä ÊÜë „ÅÑ „Åü „Å® „Çä ÊÜë„ÅÑ„Åü ‰Ωï„Åã „Åå'\n",
        "  # line = 'ÈªÑÊ≥â „ÅÆ ÂõΩ „Å∏ „ÅÆ„Åø „Å° „Å•„Çå „Å´'\n",
        "  # line = '„Çâ„Çâ„Çâ„Çâ „Çâ„Çì „Çâ„Çâ„Çâ„Çâ „Çâ„Çì Ë∏ä„Çä Ë∏ä„Çä Ë∏ä„Çç„ÅÜ„Çà'\n",
        "  # line = '„Å© „Åì„Å´„ÇÇ „ÅÑ „Åë„Å™„ÅÑÁîü„Åæ„Çå„Åü „Å®„Åç „Åã„Çâ'\n",
        "  # line= '„Å© „Åì„Å´„ÇÇ „ÅÑ „Åë„Å™„ÅÑÁîü„Åæ„Çå„Åü „Å®„Åç „Åã„Çâ'\n",
        "  # line = '„Åì „Çå„Åã„Çâ„Åï „Åì„Çå„Åã„Çâ „Åï ‰ºö„Åà„Çã „Åç„Åø „Å® Á¥ÑÊùü „Åô„Çã „Çà'\n",
        "  # line = '„Åì „Çå„Åã„Çâ„ÇÇ „Åì „Çå„Åã„Çâ„ÇÇ „Åº „Åè„Åå „Åö„Å£„Å® „ÅÑ„Å°„Å∞„Çì„Å™ „Çì„Å†'\n",
        "  # line = '„ÅÇ„ÅÇÁ•ûÊßòÂ≠ê„Å©„ÇÇ„ÅÆÁ•ûÊßò'\n",
        "  # line = 'ÁõÆ„Åå„Åµ„Çâ„Åµ„ÇâÈü≥„ÇÇ„Åµ„Å´„ÇÉ„Åµ„Å´„ÇÉ'\n",
        "  \n",
        "  \n",
        "  j,k = translating(line.replace(' ',''))\n",
        "  if len(k.split())<2:\n",
        "    clear()\n",
        "    print(line+'\\n')\n",
        "    real = input('IS THIS REALLY JAPANESE OR CHINESE????: YES: [ENTER], NO: [X]\\n')\n",
        "    clear()\n",
        "    if real in empty_list:\n",
        "      print('Ok... THIS IS \"JAPANESE OR CHINESE\"')\n",
        "    else:\n",
        "      print('FOUND THE KOREAN....')\n",
        "      j,k = translating(line)\n",
        "\n",
        "\n",
        "  trans, pron = j,k.translate(str.maketrans(\"\",\"\",p2)).translate(str.maketrans(\"\",\"\",p1)).replace('-','')\n",
        "\n",
        "  liner_main = pron.lower().split()[::-1]\n",
        "  debug = 1\n",
        "  if debug==1:\n",
        "    print(line)\n",
        "    print(liner_main[::-1])\n",
        "    print('\\n')\n",
        "\n",
        "  w=''\n",
        "  character = ''\n",
        "  add_to = []\n",
        "  word_gotten = 0\n",
        "\n",
        "  for character in line[::-1]:\n",
        "    w=character+w\n",
        "    \n",
        "    t, p = translating('('+line+')'+sep+w)\n",
        "    p = p.lower().split(sep.replace(' ',''))[-1].lstrip('-.,').strip().translate(str.maketrans(\"\",\"\",p2)).translate(str.maketrans(\"\",\"\",p1)).replace('-','')\n",
        "    \n",
        "    liner = liner_main[word_gotten:word_gotten+1]\n",
        "    if debug ==1:\n",
        "      # print('w [',w,'] character [',character,'] p [',p,'] liner',liner,'gotten [',word_gotten,']')\n",
        "      print('[',w,'] <-- [',character,']                  [',p,'] <--> ',liner,' [',word_gotten,']')\n",
        "      # print('add_to',add_to)\n",
        "      \n",
        "      \n",
        "\n",
        "    if p in liner:\n",
        "      if debug==1:\n",
        "        print('------type 1----------natural match---------')\n",
        "        \n",
        "      add_to = [w]+add_to\n",
        "      w=''\n",
        "      word_gotten+=1\n",
        "      print(add_to,'[',word_gotten,']\\n')\n",
        "      continue\n",
        "    \n",
        "    \n",
        "    if ''.join(p.split()) in liner:\n",
        "      if debug==1:\n",
        "        print('------type 2----------separately match---------')\n",
        "      add_to =[w]+add_to\n",
        "      w=''\n",
        "      word_gotten+=1\n",
        "      print(add_to,'[',word_gotten,']\\n')\n",
        "      continue\n",
        "    \n",
        "    if liner == []:\n",
        "      if debug==1:\n",
        "        print('------type Y----------residual trailing match---------')\n",
        "      \n",
        "      add_to = [w+add_to[0]]+add_to[1:]\n",
        "      w=''\n",
        "      print(add_to,'[',word_gotten,']\\n')\n",
        "      continue\n",
        "\n",
        "    # if ''.join(p.split())[1:] == liner[0][1:]:\n",
        "    #   if debug==1:\n",
        "    #     print('------type 3----------partial separate match---------')\n",
        "      \n",
        "    #   add_to = [w]+add_to\n",
        "    #   w=''\n",
        "    #   word_gotten+=1\n",
        "    #   print(add_to,'[',word_gotten,']\\n')\n",
        "    #   continue\n",
        "\n",
        "      \n",
        "\n",
        "    if len(p.split())>1:\n",
        "    \n",
        "      if len(p.split())==2 and len(w)==2 and p.split()[-1] in liner:\n",
        "        if debug==1:\n",
        "          print('------type 4----------second word match---------')\n",
        "    \n",
        "        add_to = [w[1:]]+add_to\n",
        "        w=w[0]\n",
        "        word_gotten+=1\n",
        "        print(add_to,'[',word_gotten,']\\n')\n",
        "      if p.split()[0] in liner_main[word_gotten:word_gotten+1]:\n",
        "        if debug==1:\n",
        "          print('------type 5----------further second word match---------')\n",
        "\n",
        "        add_to = [w]+add_to\n",
        "        w=''\n",
        "        word_gotten+=1\n",
        "      \n",
        "        print(add_to,'[',word_gotten,']\\n')\n",
        "        continue\n",
        "      else:\n",
        "        continue\n",
        "    \n",
        "    \n",
        "  if w!= '':\n",
        "    if debug==1:\n",
        "      print('[',w,'] <-- [',character,']                  [',p,'] <--> ',liner)\n",
        "      print('------type X----------bad match---------')\n",
        "\n",
        "    w=w.strip()\n",
        "    if len(w.split())==len(p):\n",
        "      for item in w.split()[::-1]:\n",
        "        add_to = [w]+add_to\n",
        "        # w=''\n",
        "        word_gotten+=1  \n",
        "    else:\n",
        "      if debug ==1:\n",
        "        print('------type MEGA ULTRA PSYCHO CRAZY ULTIMATE----------bad match---------')\n",
        "      line1 = w\n",
        "      j1,k1 = translating(line1)\n",
        "      trans1,pron1 = j1,k1.translate(str.maketrans(\"\",\"\",p2)).translate(str.maketrans(\"\",\"\",p1)).replace('-','')\n",
        "      liner_main1 = pron1.lower().split()\n",
        "      w1 = ''\n",
        "      character1 = ''\n",
        "      add_to1 = []\n",
        "      word_gotten1 = 0 \n",
        "\n",
        "      for character1 in line1:\n",
        "        w1=w1+character1\n",
        "        print(w1)\n",
        "        t1,p11 = translating('('+line1+')'+sep+w1)\n",
        "        p11 = p11.lower().split(sep.replace(' ',''))[-1].lstrip('-.,').strip().translate(str.maketrans(\"\",\"\",p2)).translate(str.maketrans(\"\",\"\",p1)).replace('-','')\n",
        "        # print(p11)\n",
        "        liner1 = liner_main1[word_gotten1:word_gotten1+1]\n",
        "        if debug ==1:\n",
        "          # print('w [',w,'] character [',character,'] p [',p,'] liner',liner,'gotten [',word_gotten,']')\n",
        "          print('[',w1,'] <-- [',character1,']                  [',p11,'] <--> ',liner1,' [',word_gotten1,']')\n",
        "        if p11 in liner1:\n",
        "          if debug==1:\n",
        "            print('------type 1----------natural match---------')\n",
        "          add_to1 += [w1]\n",
        "          w1=''\n",
        "          word_gotten1+=1\n",
        "          print(add_to1,'[',word_gotten1,']\\n')\n",
        "          continue\n",
        "\n",
        "      if w1!= '':\n",
        "        add_to1 +=[w1]\n",
        "\n",
        "      add_to = add_to1+add_to\n",
        "\n",
        "    if debug ==1:\n",
        "    # print('w [',w,'] character [',character,'] p [',p,'] liner',liner,'gotten [',word_gotten,']')\n",
        "      \n",
        "      print(add_to,'[',word_gotten,']\\n')\n",
        "\n",
        "  clear()\n",
        "  #########################################################\n",
        "  w = ''\n",
        "  for item in add_to:\n",
        "    w+=item.strip()+' '\n",
        "  w = w.strip()\n",
        "  if debug == 1:\n",
        "    print('\\n----words-'+str(len(w.split()))+'--total_character---'+str(len(w.replace(' ','')))+'-----\\n')\n",
        "    print(w.split())\n",
        "    print(pron.lower().split())\n",
        "    print('\\n----words-'+str(len(pron.split()))+'--total_character---'+str(len(line.replace(' ','')))+'-----\\n')\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "###################################################################################################################################################\n",
        "  if len(w.replace(' ',''))!= len(line.replace(' ','')):\n",
        "    clear()\n",
        "    print('PROOOOOOOOOOOOOOBLEM!!!!!!!!!!!!!!!!!')\n",
        "    print('OG line length:',len(line.replace(' ','')),'Output line lenght:',len(w.replace(' ','')))\n",
        "\n",
        "    display(line)\n",
        "    display(w)\n",
        "    display(add_to)\n",
        "    display(k.lower().split())\n",
        "    # print()\n",
        "    time.sleep(1)\n",
        "    os.kill(os.getpid(),9)\n",
        "  else:\n",
        "    sk = to_json({},'translation_database','read')\n",
        "    try:\n",
        "      sk[w]['pronounciation']=pron\n",
        "      to_json(sk,'translation_database','write')\n",
        "    except KeyError:\n",
        "      sk[w]={'main':w,\n",
        "      'translation':j,\n",
        "      'pronounciation':pron}\n",
        "      to_json(sk,'translation_database','write')\n",
        "  \n",
        "  return w"
      ],
      "metadata": {
        "id": "b15Zg_dJH90R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5G75AAOOESm"
      },
      "outputs": [],
      "source": [
        "def edit_the_translation_manual_style(rewrite):\n",
        "  import openpyxl\n",
        "  from openpyxl import load_workbook\n",
        "  from openpyxl.comments import Comment\n",
        "  import pandas as pd\n",
        "\n",
        "  writer = wb = df = sh = ''\n",
        "  documents_folder = '/content/drive/MyDrive/essentials/unlimited_ssm/---archive---/documents/'\n",
        "  translate_excel = documents_folder+'translate_excel.xlsx'\n",
        "  name = str(done_dl[index]['file_index'])+sep+done_dl[index]['file_name'].replace('\\u200b','')\n",
        "  if rewrite not in empty_list:\n",
        "    print('OVERWRITING........')\n",
        "    t = get_current_songs_lyrics_translation_dictionary()\n",
        "    writer = pd.ExcelWriter(documents_folder+'translate_excel.xlsx',engine='xlsxwriter')\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    mains = ''\n",
        "    trans = ''\n",
        "    prons = ''\n",
        "    for item in t:\n",
        "      if item not in empty_list:\n",
        "        # print(item)\n",
        "        mains+=t[item]['main']+'\\n'\n",
        "        prons+=t[item]['pronounciation']+'\\n'\n",
        "        trans+=t[item]['translation']+'\\n'\n",
        "    \n",
        "    df['main'] = pd.DataFrame(mains.split('\\n'))\n",
        "    df['pronounciation'] = pd.DataFrame(prons.split('\\n'))\n",
        "    df['translation'] = pd.DataFrame(trans.split('\\n'))\n",
        "    df.to_excel(writer,sheet_name='Index - '+index,index=False)\n",
        "\n",
        "\n",
        "    wb = writer.book\n",
        "    sheet = writer.sheets['Index - '+index]\n",
        "    sheet.set_column(0,0,20,wb.add_format({'text_wrap':True}))\n",
        "    sheet.set_column(1,1,20,wb.add_format({'text_wrap':True}))\n",
        "    sheet.set_column(2,2,20,wb.add_format({'text_wrap':True}))\n",
        "    # sheet.set_column(3,3,20,wb.add_format({'text_wrap':True}))\n",
        "\n",
        "\n",
        "    writer.save()\n",
        "    \n",
        "    writer = wb = df = sh = ''\n",
        "    wb = load_workbook(translate_excel, data_only=True)\n",
        "    sh = wb['Index - '+index]\n",
        "    sh.freeze_panes = \"A2\"\n",
        "    wb.save(translate_excel)\n",
        "\n",
        "\n",
        "  print('Edit the translation for',name+'\\n')\n",
        "  print('The excel sheet, helpful formula')\n",
        "  display('=GOOGLETRANSLATE(A2)','=GOOGLETRANSLATE(SUBSTITUTE(A2,\" \",\"\"))','=IF(IF(A2=\"\",\"\",COUNTA(SPLIT(A2,\" \")))=IF(B2=\"\",\"\",COUNTA(SPLIT(B2,\" \"))),\"same\",\"not same\")','=IF(A2=\"\",\"\",COUNTA(SPLIT(A2,\" \")))','IF(B2=\"\",\"\",COUNTA(SPLIT(B2,\" \")))')\n",
        "  print('\\nhttps://docs.google.com/spreadsheets/d/1DvzArPis4JKqYyTrGBAKMQ0KLtUg9QWE')\n",
        "  time.sleep(2)\n",
        "  done = input('\\n\\nAfter editing is enter: 856953\\n')\n",
        "  if done == '856953':\n",
        "    writer = wb = df = sh = pd = ''\n",
        "    # print('Waiting 3 minutes so files are synced....')\n",
        "    # time.sleep(3*60)\n",
        "    import pandas as pd\n",
        "    \n",
        "    df = pd.read_excel(translate_excel)\n",
        "    h = to_json({},'translation_database','read')\n",
        "    for i in range(len(df)):\n",
        "      \n",
        "      main = df.iloc[i]['main']\n",
        "      try:\n",
        "        line = re.sub('‚Äò','\\'',main)\n",
        "        line = re.sub('‚Äú','\"',line)\n",
        "        line = re.sub('‚Äù','\"',line)\n",
        "        line = re.sub('‚Äô','\\'',line)\n",
        "        main = line\n",
        "      except Exception as e:\n",
        "        continue\n",
        "      trans = df.iloc[i]['translation']\n",
        "      pron = df.iloc[i]['pronounciation']\n",
        "      h[main]={'main':main,\n",
        "              'translation':trans,\n",
        "              'pronounciation':pron}\n",
        "    to_json(h,'translation_database','write')\n",
        "    return df\n",
        "  else:\n",
        "    # l=1\n",
        "    print('Not saving anything')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EHBS9VQhOGy"
      },
      "outputs": [],
      "source": [
        "def get_current_songs_lyrics_translation_dictionary():\n",
        "  t=  {}\n",
        "  for item in lyrics.split('\\n'):\n",
        "    if item not in empty_list:\n",
        "      a,b = translating(item)\n",
        "      t[item]={'main':item,\n",
        "              'translation':a,\n",
        "              'pronounciation':b}\n",
        "  return t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checktd()"
      ],
      "metadata": {
        "id": "pEYvjeHse3dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQlEjCacUeHM"
      },
      "outputs": [],
      "source": [
        "#### CTRL+F8.\n",
        "done_dl= update_dl()\n",
        "before = len(to_json({},'translation_database','read'))\n",
        "sid_or_slsd = input('LYRICS: 1, SYNC LYRICS: [ENTER]\\n')\n",
        "if sid_or_slsd in empty_list:\n",
        "# slsd_lyrics = to_json({},sid,'read')\n",
        "  index = input('SONG [SLSD LYRICS] INDEX:: ')\n",
        "  slsd_lyrics = to_json({},slsd,'read')[index]\n",
        "  lyrics = lyr_data_to_lyrics()\n",
        "else:\n",
        "  slsd_lyrics = to_json({},sid,'read')\n",
        "  index = input('SONG [SID LYRICS] INDEX:: ')\n",
        "  lyrics = sid_data_to_lyrics()\n",
        "the_response_from_google,g_list=lyrics_translator(lyrics)\n",
        "clear()\n",
        "print('\\n\\n',before,sep,len(to_json({},'translation_database','read')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(to_json({},slsd,'read'))"
      ],
      "metadata": {
        "id": "R49_msBo-wAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(to_json({},sid,'read'))\n",
        "play_another_video('')"
      ],
      "metadata": {
        "id": "PEhdGBMMkBcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOY_8pzW3opx"
      },
      "outputs": [],
      "source": [
        "\n",
        "####ONLY TO SAVE SLSD EDITS\n",
        "###1 TO OVERWRITE, EMPTY DOESNT\n",
        "# index = str(play_audio(1)['file_index'])\n",
        "# index = '2212'\n",
        "overwrite = ''\n",
        "\n",
        "slsd_lyrics = to_json({},slsd,'read')[index]\n",
        "lyrics = lyr_data_to_lyrics()\n",
        "# clear()\n",
        "\n",
        "writer=wb=sh=df=pd=''\n",
        "try:\n",
        "  df = edit_the_translation_manual_style(overwrite)\n",
        "except FileNotFoundError:\n",
        "  clear()\n",
        "  print('SOMETHING WENT WRONG!!!!!!!!!\\n')\n",
        "  time.sleep(5)\n",
        "  df = edit_the_translation_manual_style('')\n",
        "# clear()\n",
        "df\n",
        "# for item in lyrics.split('\\n'):\n",
        "#   if item not in empty_list:85\n",
        "#     display(item)\n",
        "#     print(sep.join(translating(item)[::-1])+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Pandora, ah,\"\n",
        "s = re.sub(\"[\\s\\.,]+(?=$)\",\"\",s)\n",
        "display(s)"
      ],
      "metadata": {
        "id": "61NtnkrUYRPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_another_video('')\n",
        "# to_json({},'translation_database','read')['Nawma sa‚Äônokur m√¨fa oey√§']\n",
        "# checktd()\\"
      ],
      "metadata": {
        "id": "NIRF_C-em2Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in lyrics.split('\\n'):\n",
        "  a,b = translating(item)\n",
        "\n",
        "  print(item,'\\n',b,sep,a+'\\n')"
      ],
      "metadata": {
        "id": "mN0OD172kvPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfntgdh71QWw"
      },
      "outputs": [],
      "source": [
        "# #IF JAPANESE AND CHINESE THEN \n",
        "# ###BTRL\n",
        "# index = str(play_audio(1)['file_index'])\n",
        "# # lyrics_word_splitter(1) ### FIRST TRANSLATE THE LYRICS\n",
        "slsd_splitter_after_lyrics_is_split() #### DO THIS AFTER THE SYNC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# play_another_video(1)\n",
        "\n",
        "# checktd()\n",
        "\n",
        "len(to_json({},'translation_database','read'))"
      ],
      "metadata": {
        "id": "uY2xTKGsJAkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_another_video('')"
      ],
      "metadata": {
        "id": "l5teHwEVjhkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zaSg9utg4yI"
      },
      "outputs": [],
      "source": [
        "main = \"I'm not the devil\"\n",
        "tran = main\n",
        "pron = main\n",
        "\n",
        "t = to_json({},'translation_database','read')\n",
        "t[main]={'main':main,\n",
        "         'translation':tran,\n",
        "         'pronounciation':pron}\n",
        "to_json(t,'translation_database','write')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl7JyY387-hW"
      },
      "outputs": [],
      "source": [
        "for item in lyrics.split('\\n'):\n",
        "  if item not in empty_list and item not in ['\\u200b','\\u200b\\u200b']:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szofjntyJmI9"
      },
      "outputs": [],
      "source": [
        "# play_audio(\"\")\n",
        "# # display(len(os.listdir(key_destination)),(os.listdir(key_destination)[::-1]))\n",
        "#   # time.sleep()\n",
        "#   # clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqXlVCk67gE2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwQR1-tdLYh4"
      },
      "outputs": [],
      "source": [
        "####REMOVES CURRENT SONG FROM TRANSLATION DATABASE\n",
        "for item in lyrics.split('\\n'):\n",
        "  print(item)\n",
        "  # a,b = translating(item)\n",
        "  t = to_json({},'translation_database','read')\n",
        "  try:\n",
        "    t.pop(item)\n",
        "  except KeyError:\n",
        "    continue\n",
        "  to_json(t,'translation_database','write')\n",
        "  # print(a,b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jefs92_T65Uj"
      },
      "outputs": [],
      "source": [
        "# # index = ''\n",
        "# index = '1963'\n",
        "# lyrics = to_json({},sid,'read')[index]['lyrics']\n",
        "# # lyrics = input()\n",
        "# res = 600\n",
        "# cd = colors(lyrics)\n",
        "# ssm = matrix(lyrics,'',cd)\n",
        "# pattern  = making_pattern(ssm,'x',res)\n",
        "# pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE2goCGeTUaI"
      },
      "outputs": [],
      "source": [
        "# ssm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_XF5Cf8M0yz"
      },
      "outputs": [],
      "source": [
        "#shower\n",
        "done_dl = update_dl()\n",
        "show_song_list(2)\n",
        "# play_another_video('')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1j4Twa2Pn7F9UjLwml8_BkJcwomxqYU75",
      "authorship_tag": "ABX9TyNMWN1jtG7tPlh1EQT9cP/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}